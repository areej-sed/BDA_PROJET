# Streaming Taxi avec Kafka, MongoDB et Cassandra

Projet du module **BDABD**

PrÃ©parÃ© par : 
SEDDIKI Aridj
BOUREKIA Nihad
KALACHE Rachid Abdelghafour
---

Lien du rapport de projet : https://shorturl.at/sqPn4

---

## 1. Description du projet

Ce projet vise Ã  concevoir et tester un pipeline Big Data temps rÃ©el pour les flux NYC Taxi. Kafka est utilisÃ© pour le streaming, tandis que MongoDB et Cassandra servent au stockage et Ã  lâ€™analyse des donnÃ©es. Lâ€™objectif est de maÃ®triser le traitement en streaming, la modÃ©lisation NoSQL, et dâ€™Ã©valuer les performances et la scalabilitÃ© des clusters, le tout orchestrÃ© via Docker.
---

## 1.1 Structure du projet

Voici l'arborescence des fichiers importants et leur description :

```
BDA_PROJET/
â”œâ”€â”€ data/                       # Dossier de stockage des donnÃ©es
â”‚   â”œâ”€â”€ input/                  # DonnÃ©es brutes (Parquet, Shapefiles)
â”‚   â””â”€â”€ output/                 # DonnÃ©es traitÃ©es (JSON)
â”‚
â”œâ”€â”€ data_preparation/           # Scripts de prÃ©paration des donnÃ©es
â”‚   â””â”€â”€ data_preprocessing.ipynb # Notebook principal pour le nettoyage et la conversion des donnÃ©es
â”‚
â”œâ”€â”€ docker/                     # Configuration des conteneurs Docker
â”‚   â”œâ”€â”€ cassandra/              # Environnement Cassandra
â”‚   â”‚   â”œâ”€â”€ docker-compose_cassandra.yml
â”‚   â”‚   â””â”€â”€ schema.cql          # SchÃ©ma de la base de donnÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ kafka/                  # Environnement Kafka
â”‚   â”‚   â”œâ”€â”€ consumer/           # Consumers Kafka
â”‚   â”‚   â”‚   â””â”€â”€ cassandra/      # Consumer vers Cassandra
â”‚   â”‚   â”‚       â”œâ”€â”€ consumer_cassandra.py
â”‚   â”‚   â”‚       â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”‚       â””â”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ producer/           # Producer Kafka
â”‚   â”‚   â”‚   â”œâ”€â”€ producer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ docker-compose.yml  # Cluster Kafka
â”‚   â”‚
â”‚   â””â”€â”€ mongodb/                # Environnement MongoDB
â”‚       â”œâ”€â”€ consumer/           # Consumer vers MongoDB
â”‚       â”‚   â”œâ”€â”€ consumer.py
â”‚       â”‚   â”œâ”€â”€ Dockerfile
â”‚       â”‚   â””â”€â”€ requirements.txt
â”‚       â”œâ”€â”€ docker-compose.yml  # Cluster MongoDB
â”‚       â”œâ”€â”€ init-mongo.sh
â”‚       â””â”€â”€ mongo-init.js
â”‚
â””â”€â”€ README.md                   # Documentation du projet
```

---

## 2. PrÃ©requis

Avant dâ€™exÃ©cuter lâ€™application, il est nÃ©cessaire dâ€™avoir installÃ© :

- **Python 3.8 ou supÃ©rieur**
- **pip**

- **Docker Desktop**

### BibliothÃ¨ques Python requises

- pandas
- pyarrow
- numpy
- python-dateutil
- tqdm
- ...

---

## 3. Installation et exÃ©cution

### Ã‰tape 1 : Cloner ou tÃ©lÃ©charger le projet

```bash
git clone https://github.com/areej-sed/taxi_streaming_project
cd taxi_streaming_project
```

**Ã‰tape 2 : CrÃ©er et activer un environnement virtuel (optionnel mais recommandÃ©)**

```bash
python -m venv venv
```

\*Activation

```bash
venv\Scripts\activate
```

**Ã‰tape 3 : Installer les dÃ©pendances**

```bash
pip install pandas pyarrow numpy python-dateutil tqdm
```

## 4.

## Partie 1 : PrÃ©paration des donnÃ©es

Toutes les Ã©tapes de prÃ©traitement des donnÃ©es se trouvent dans le notebook Jupyter :
**`data_preparation/data_preprocessing.ipynb`**

Les principales Ã©tapes rÃ©alisÃ©es dans ce notebook sont :
- Chargement des donnÃ©es brutes (Parquet) et des zones de taxi (Shapefile).
- Calcul des latitudes et longitudes (centroÃ¯des) Ã  partir des gÃ©omÃ©tries des zones.
- Enrichissement des donnÃ©es : jointure pour ajouter les coordonnÃ©es et les noms de quartiers (Boroughs/Zones) aux points de prise en charge et de dÃ©pose.
- SÃ©lection des colonnes pertinentes et renommage pour uniformisation.
- Ajout d'un identifiant unique `trip_id`.
- Export des donnÃ©es traitÃ©es en fichier JSON (`final_data.json`) pour l'ingestion.


## Partie 2 : Mise en place du Cluster Kafka avec Docker

**Ã‰tape 1 : Construction et DÃ©marrage du Cluster (sans Producer)**
```bash
cd docker/kafka
docker compose build
docker compose up -d zookeeper kafka1 kafka2 kafka3
```

**Ã‰tape 2 : CrÃ©ation du topic Kafka taxi.raw**

CrÃ©ation du topic :
```bash
docker exec -it kafka1 kafka-topics --create --topic taxi.raw --bootstrap-server kafka1:9092 --partitions 6 --replication-factor 2
```

VÃ©rifier les offsets (optionnel) :
```bash
docker exec -it kafka1 kafka-run-class kafka.tools.GetOffsetShell --broker-list kafka1:9092 --topic taxi.raw
```

**Ã‰tape 3 : Lancer le Producer**
```bash
docker compose up producer
```

**ArrÃªt du cluster (avec suppression des volumes)**
```bash
docker compose down -v
```

---

## Partie 3 : Cluster MongoDB (Sharding) et Consumer

**Ã‰tape 1 : DÃ©marrage du cluster**
```bash
cd docker/mongodb
docker compose build
docker compose up -d configsvr shard1 shard2 shard3 mongos mongo-init
```

**Ã‰tape 2 : VÃ©rification de l'initialisation**
```bash
docker logs -f mongo-init
```

**Ã‰tape 3 : DÃ©marrage du Consumer**
```bash
docker compose up consumer
```

**ArrÃªt du cluster (avec suppression des volumes)**
```bash
docker compose down -v
```



_Sortie attendue :_
```
âœ… Connected to MongoDB
âœ… Connected to Kafka
ðŸ”„ Listening for messages...
âœ… Inserted 100 events | Total: 100
...
```

**VÃ©rification finale : Comptage des documents**

```bash
docker exec -it mongos mongosh --eval "use taxi_streaming; db.taxi_events.countDocuments()"
```

**VÃ©rification de la distribution des donnÃ©es (Sharding)**

```bash
docker exec -it mongos mongosh --eval "use taxi_streaming; db.taxi_events.getShardDistribution()"
```

_Example de Sortie attendue :_
```
Shard shard1rs at shard1rs/mongo-shard1:27018
{
  data: '1.32MiB',
  docs: 2624,
  chunks: 2,
  'estimated data per chunk': '676KiB',
  'estimated docs per chunk': 1312
}
---
Shard shard3rs at shard3rs/mongo-shard3:27018
{
  data: '32KiB',
  docs: 73,
  chunks: 2,
  'estimated data per chunk': '16KiB',
  'estimated docs per chunk': 36
}
---
Shard shard2rs at shard2rs/mongo-shard2:27018
{
  data: '7.8MiB',
  docs: 15203,
  chunks: 2,
  'estimated data per chunk': '3.9MiB',
  'estimated docs per chunk': 7601
}
---
Totals
{
  data: '9.15MiB',
  docs: 17900,
  chunks: 6,
  'Shard shard1rs': [
    '14.43 % data',
    '14.65 % docs in cluster',
    '528B avg obj size on shard'
  ],
  'Shard shard3rs': [
    '0.34 % data',
    '0.4 % docs in cluster',
    '449B avg obj size on shard'
  ],
  'Shard shard2rs': [
    '85.22 % data',
    '84.93 % docs in cluster',
    '538B avg obj size on shard'
  ]
}
```
## Partie 4 : Mise en place du Cluster Cassandra avec Docker

**Ã‰tape 1 : Lancer le cluster Cassandra**

```bash
cd docker/cassandra
docker-compose -f docker-compose_cassandra.yml up -d
```

**VÃ©rification**

```bash
docker ps
```

**Ã‰tape 2 : Lancer le consumer pour creer et remplir les tables**

```bash
cd docker/kafka
docker compose up -d consumer_cassandra
```

